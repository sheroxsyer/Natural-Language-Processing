{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdMVFi5Y2atu"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7vazd_a6xyB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb04c15d-712f-4e33-950f-f4be0d3f8d58"
      },
      "source": [
        "import csv\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqHFHg-NoRcG"
      },
      "source": [
        "*******Reading all corpus from file into list*******"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vP95440N7ej8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b72ccad9-41d2-483f-d41c-56e48119212d"
      },
      "source": [
        "with open('/content/drive/My Drive/NLP/faiz.txt', 'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    poetry = list(reader)\n",
        "f.close()\n",
        "text = poetry[0]\n",
        "print(text)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['گلوں میں رنگ بھرے باد نوبہار چلے']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OR3KCD_Mobx_"
      },
      "source": [
        "Making a list of starting words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKBJZ1X7RyhU"
      },
      "source": [
        "f1 = \"/content/drive/My Drive/NLP/faiz.txt\"\n",
        "roman = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']\n",
        "#array containing special characters\n",
        "special = ['‘','٪٪٪٪٪٪٪٪٪٪٪٪٪٪٪٪٪٪٪٪٪٪٪٪٪٪٪٪','%%%%%%%%%%%%%%%%%%%%', '!', '`', '\"', ')', '(',\"''\", '.', ':','’’', \"'\", '\"', '؟','‘','’','‘','،','“','’']\n",
        "starting_words = []         #array to store the starting words\n",
        "fileref = open (f1,\"r\")\n",
        "line = fileref.readlines()\n",
        "fileref.close()\n",
        "\n",
        "#loop to tokenise sentences in words and store in start_words array\n",
        "for words in line:\n",
        "  word = words.split()\n",
        "  if len(word) != 0 and word[0] not in special and word[0][0] not in roman: #check for special characters and english letters. if found than they are not added to list\n",
        "    starting_words.append(word[0])\n",
        "#print(starting_words)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJVjoalQoitN"
      },
      "source": [
        "Tokenizing the corpus into a word list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGluNdqW9X81"
      },
      "source": [
        "w_list = []\n",
        "special = ['‘','‘‘','٪','٪٪٪٪٪٪٪٪٪٪٪٪٪٪٪٪٪٪٪٪٪٪٪٪٪٪٪٪','%%%%%%%%%%%%%%%%%%%%', '!', '%', '`', '\"', ')', '(',\"''\", '.', ':','’’', \"'\", '\"', '؟','‘','’','‘','،','“','’']\n",
        "#nested loop to tokenise the whole corpus into words and stored in a word list\n",
        "for i in range(len(poetry)-1):\n",
        "  text = poetry[i]\n",
        "  for word in text:\n",
        "    s = word.split()\n",
        "    for w in s:\n",
        "      if w not in special:  #check so no special characters are added\n",
        "        w_list.append(w)\n",
        "#print(w_list)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrCOvmqbo00_"
      },
      "source": [
        "Probability calculation for Bigrams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pZ8HQ6_H0VG"
      },
      "source": [
        "def prob(w_list, s):\n",
        "  p = 0\n",
        "  p1 = 0\n",
        "  count = 0\n",
        "  w1_count = 0    #to store total occurances of the starting word\n",
        "  visited = []\n",
        "  max_prob = []   #to store probabilities of all possible combinations\n",
        "  word = ''\n",
        "  w1 = s\n",
        "\n",
        "  for i in range(len(w_list)-1):  #counting total occurances of starting word in the corpus\n",
        "    if w1 == w_list[i]:\n",
        "      w1_count += 1\n",
        "  for i in range(len(w_list)-1):\n",
        "    w = w_list[i]\n",
        "    if w == w1:\n",
        "      w2 = w_list[i+1]\n",
        "      if w2 not in visited:\n",
        "        visited.append(w2)\n",
        "        for j in range(len(w_list)-1):\n",
        "          if w1 == w_list[j] and w2 == w_list[j+1]:\n",
        "            p += 1\n",
        "        if p > p1:              #storing the word with the highest count\n",
        "          word = w2\n",
        "          p1 = p\n",
        "        count = p/w1_count\n",
        "        max_prob.append(count)\n",
        "        p = 0\n",
        "  return word"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJPdBJy3o619"
      },
      "source": [
        "Generating poetry through Bigram Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4CMzlTr4GGu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "526bd818-d93d-4e3a-f29b-052614fb8ed2"
      },
      "source": [
        "import random\n",
        "start = random.choice(starting_words)   #generating random starting word\n",
        "next_word = ''\n",
        "verse = ''\n",
        "verse = verse + start\n",
        "next_word = prob(w_list, start)     #getting the second most probable word\n",
        "counter = 2\n",
        "verse = verse + ' ' + next_word\n",
        "verse_count = random.randint(5,8)\n",
        "for s in range(3):\n",
        "  for v in range(4):\n",
        "    for i in range (verse_count):\n",
        "      res = prob(w_list, next_word)\n",
        "      verse = verse + ' ' + res     #adding it to the verse\n",
        "      next_word = res\n",
        "      counter += 1\n",
        "      if counter == verse_count:\n",
        "        #print(verse_count)\n",
        "        print(verse)\n",
        "        verse = ''\n",
        "        next_word = random.choice(starting_words) #generating starting word for the next verse\n",
        "        verse = verse + next_word\n",
        "        verse_count = random.randint(7,9)\n",
        "        counter = 1\n",
        "        break\n",
        "  print()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "حسن مرہون جوش بادۂ ناز عشق کا ہر\n",
            "دامن نچوڑ دیں تو نہیں تھا اب کے\n",
            "تو نہیں تھا اب کے دیکھ لیا دل کا\n",
            "اک عمر کے دیکھ لیا دل کا ہر صدا\n",
            "\n",
            "دل کا ہر صدا پر ہے یارو\n",
            "کیوں دادِ غم گسار چلے تو نہیں تھا اب\n",
            "گنو سب کی طرح اپنی خامشی گونجی گویا ہر\n",
            "رت بدلنے لگی تھی راہ میں پھر ایک\n",
            "\n",
            "ایک بار اور کیا کیا کیا کیا کیا کیا\n",
            "فصل گل کے دیکھ لیا دل کا ہر\n",
            "اسی انداز سے دل کا ہر صدا پر\n",
            "بے نقاب آئے اس طرح اپنی خامشی\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wRGkVx4o_GA"
      },
      "source": [
        "Probability function for Trigram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66yaAJZ9ammY"
      },
      "source": [
        "def tri_prob(w_list,r, r1):\n",
        "  p = 0\n",
        "  p1 = 0\n",
        "  count = 0\n",
        "  w1_count = 0\n",
        "  w3_count = 0\n",
        "  w2_count = 0\n",
        "  w2_visited = []\n",
        "  w3_visited = []\n",
        "  max_prob = []\n",
        "  max_prob2 = []\n",
        "  word = ''\n",
        "  word2 = ''\n",
        "  w1 = r\n",
        "  for i in range(len(w_list)-1):    #getting the total occurances of starting word\n",
        "    if w1 == w_list[i]:\n",
        "      w1_count += 1\n",
        "  for i in range(len(w_list)-1):\n",
        "    w = w_list[i]\n",
        "    if w == w1:\n",
        "      w2 = r1\n",
        "      if w2 not in w2_visited:\n",
        "        w2_visited.append(w2)\n",
        "        for j in range(len(w_list)-1):\n",
        "          if w1 == w_list[j] and w2 == w_list[j+1]:     #getting most probable second word\n",
        "            p += 1\n",
        "          if p > p1:\n",
        "            word = w2\n",
        "            p1 = p\n",
        "          count = p/w1_count\n",
        "          max_prob.append(count)\n",
        "          p = 0\n",
        "\n",
        " #resetting all counters\n",
        "  p = 0\n",
        "  p1 = 0\n",
        "  count = 0\n",
        "  for i in range(len(w_list)-1):\n",
        "    w = w_list[i]\n",
        "    w2 = w_list[i+1]\n",
        "    if w == w1 and w2 == word:\n",
        "      w3 = w_list[i+2]\n",
        "      for i in range(len(w_list)-1):   #get total occurance sof the third word in the whole corpus\n",
        "        if w3 == w_list[i]:\n",
        "          w3_count += 1\n",
        "      if w3 not in w3_visited:\n",
        "        w3_visited.append(w3)\n",
        "        for j in range(len(w_list)-1):\n",
        "          if w1 == w_list[j] and w2 == w_list[j+1] and w3 == w_list[j+2]: #all words found consectively\n",
        "            p += 1\n",
        "          if p > p1:\n",
        "            word2 = w3\n",
        "            p1 = p\n",
        "          count = p/w3_count\n",
        "          max_prob2.append(count)\n",
        "          p = 0\n",
        "  return word2"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2o2zOdHQpHds"
      },
      "source": [
        "Generating Poetry through Trigram Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-_r8dMJvMJN",
        "outputId": "ab54f31d-7817-44bb-b0f2-6f6d42bc8e72"
      },
      "source": [
        "import random\n",
        "res1 = ''\n",
        "res = ''\n",
        "next_word = ''\n",
        "verse = ''\n",
        "counter = 0\n",
        "done = []\n",
        "verse_count = random.randint(5,8)#randomly generating words per verse\n",
        "print_count = 0\n",
        "for s in range(3):\n",
        "  for v in range(4):\n",
        "    if print_count == 1 or print_count == 0:\n",
        "      start = random.choice(starting_words)\n",
        "      done.append(start)\n",
        "      while (start in done):\n",
        "        start = random.choice(starting_words)\n",
        "      res = start\n",
        "      verse = verse + start\n",
        "      next_word = prob(w_list, start)\n",
        "      res1 = next_word\n",
        "      verse = verse + ' ' + next_word\n",
        "      counter += 2\n",
        "      print_count = 2\n",
        "    if print_count > 1:   #if not start of a new verse\n",
        "      for i in range (verse_count):\n",
        "        next_word = tri_prob(w_list, res, res1)\n",
        "        res = res1\n",
        "        res1 = next_word\n",
        "        verse = verse + ' ' + res1\n",
        "        counter += 1\n",
        "        print_count += 1\n",
        "        if counter == verse_count:\n",
        "          print(verse)\n",
        "          verse = ''\n",
        "\n",
        "          print_count = 1\n",
        "          verse_count = random.randint(7,10)\n",
        "          counter = 0\n",
        "  print()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "اور کیا دیکھنے کو باقی ہے آپ سے\n",
            " دل لگا کے دیکھ لیا دل بہت\n",
            " کچھ جلا کے دیکھ لیا دل بہت\n",
            " کچھ جلا کے دیکھ لیا دل بہت\n",
            "\n",
            " کچھ جلا کے دیکھ لیا دل بہت\n",
            " کچھ جلا کے دیکھ لیا دل بہت کچھ جلا کے\n",
            " دیکھ لیا دل بہت کچھ جلا کے\n",
            " دیکھ لیا دل بہت کچھ جلا کے دیکھ\n",
            "\n",
            " لیا دل بہت کچھ جلا کے دیکھ لیا دل بہت\n",
            " کچھ جلا کے دیکھ لیا دل بہت کچھ\n",
            " جلا کے دیکھ لیا دل بہت کچھ جلا کے دیکھ\n",
            " لیا دل بہت کچھ جلا کے دیکھ لیا\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rj2JHv9qsxoM"
      },
      "source": [
        "Probabilty function for Backward Bigram\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gCCb5bCrzM5"
      },
      "source": [
        "def back_prob(w_list, s):\n",
        "  p = 0\n",
        "  p1 = 0\n",
        "  count = 0\n",
        "  w1_count = 0    #to store total occurances of the starting word\n",
        "  visited = []\n",
        "  max_prob = []   #to store probabilities of all possible combinations\n",
        "  word = ''\n",
        "  w1 = s\n",
        "\n",
        "  for i in range(len(w_list)-1):  #counting total occurances of starting word in the corpus\n",
        "    if w1 == w_list[i]:\n",
        "      w1_count += 1\n",
        "  for i in range(len(w_list)-1):\n",
        "    w = w_list[i]\n",
        "    if w == w1:\n",
        "      w2 = w_list[i-1]\n",
        "      if w2 not in visited:\n",
        "        visited.append(w2)\n",
        "        for j in range(len(w_list)-1):\n",
        "          if w1 == w_list[j] and w2 == w_list[j-1]:\n",
        "            p += 1\n",
        "        if p > p1:              #storing the word with the highest count\n",
        "          word = w2\n",
        "          p1 = p\n",
        "        count = p/w1_count      #calculating the probability\n",
        "        max_prob.append(count)\n",
        "        p = 0\n",
        "  return word"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j788esCtpWzc"
      },
      "source": [
        "Generating Peotry through Backward Bigram model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkrV3Su6sAdS",
        "outputId": "610d2670-736d-4ef2-d3cd-f00189e5e1e2"
      },
      "source": [
        "import random\n",
        "start = random.choice(w_list) #generating random word from the word list\n",
        "next_word = ''\n",
        "verse = ''\n",
        "verse = verse + start               #adding starting word to the verse\n",
        "next_word = back_prob(w_list, start)     #getting the second most probable word\n",
        "counter = 2\n",
        "verse = next_word + ' ' + verse\n",
        "verse_count = random.randint(5,8)\n",
        "for s in range(3):\n",
        "  for v in range(4):\n",
        "    for i in range (verse_count):\n",
        "      res = back_prob(w_list, next_word)\n",
        "      verse = res + ' ' + verse\n",
        "      next_word = res\n",
        "      counter += 1\n",
        "      if counter == verse_count:\n",
        "        print(verse)\n",
        "        verse = ''\n",
        "        next_word = random.choice(w_list)\n",
        "        verse = verse + next_word\n",
        "        verse_count = random.randint(7,9)\n",
        "        counter = 1\n",
        "        break\n",
        "  print()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ترے کنج لب سے دل میں پھر ایک\n",
            "میں کوئی دروازہ کھلا آخر شب لمس جانانہ\n",
            "باد نوبہار چلے کبھی تو وہ نشاط آہ سحر\n",
            "تو صبح ترے کنج لب سے دل میں\n",
            "\n",
            "کیا کیا کیا کیا کیا کیا نہ تھے\n",
            "باد نوبہار چلے کبھی تو صبح ترے کنج لب\n",
            "ہی سہی تمہارے نام پہ سر بسر منزل\n",
            "کیا کیا کیا کیا کیا کیا کیا جانیے\n",
            "\n",
            "سے دل ریزہ گنوا دیا جو رکے\n",
            "کبھی تو صبح ترے کنج لب سے دل سنبھالے\n",
            "کیا کیا کیا کیا کیا کیا کیا نہ\n",
            "کیا کیا کیا کیا کیا نہ کھینچ\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbhBgyhhuFPe"
      },
      "source": [
        "Generating Poetry through Bidirectional Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azQJZcYlvixV",
        "outputId": "7294f3ff-b925-492c-ead2-bd957646daa6"
      },
      "source": [
        "import random\n",
        "start = random.choice(w_list) #selecting a random word from the word list\n",
        "next_word = ''\n",
        "verse = ''\n",
        "verse = verse + start               #adding starting word to the verse\n",
        "counter = 1\n",
        "next_word = start\n",
        "verse_count = random.randint(4,5)\n",
        "for s in range(3):\n",
        "  for v in range(4):\n",
        "    for i in range (verse_count):\n",
        "      res = prob(w_list, start)\n",
        "      verse = verse + ' ' + res\n",
        "      start = res\n",
        "      res1 = back_prob(w_list, next_word) #getting the next most probable backward bigram word\n",
        "      verse = res1 + ' ' + verse    #adding word to the right of verse\n",
        "      next_word = res1\n",
        "      counter += 1\n",
        "      if counter == verse_count:\n",
        "        print(verse)\n",
        "        verse = ''\n",
        "        start = random.choice(w_list) #generating starting word for the next verse\n",
        "        verse = verse + start\n",
        "        verse_count = random.randint(4,5)          #generating random number for the # of words in a verse\n",
        "        counter = 1\n",
        "        break\n",
        "  print()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "لب سے ماہتاب اترے دست دعا آخر شب سر\n",
            "صبح ترے کنج اے جان پر ہے\n",
            "نوبہار چلے کبھی تو صف دشمناں کو باقی ہے\n",
            "رنگ بھرے باد جام ارغواں کی طرح\n",
            "\n",
            "لب سے دل میں رکے تو نہیں تھا اب\n",
            "صبح ترے کنج آسماں سارے زمانے بھول\n",
            "نوبہار چلے کبھی تو آخر شب سر شام وہ\n",
            "میں رنگ بھرے باد ہنسائیاں کیا کیا کیا کیا\n",
            "\n",
            "لب سے دل دل کا ہر صدا\n",
            "تو صبح ترے کنج یہ دل کا ہر صدا\n",
            "نوبہار چلے کبھی داغ پر ہے یارو\n",
            "رنگ بھرے باد اس طرح اپنی خامشی\n",
            "\n"
          ]
        }
      ]
    }
  ]
}